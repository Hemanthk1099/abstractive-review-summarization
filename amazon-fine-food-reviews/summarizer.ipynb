{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import re           \n",
    "from bs4 import BeautifulSoup \n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords   \n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\hemanth\\venvs\\3.6.8\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hemanth\\venvs\\3.6.8\\lib\\site-packages (from bs4) (4.8.2)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\hemanth\\venvs\\3.6.8\\lib\\site-packages (from beautifulsoup4->bs4) (1.9.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Reviews.csv',nrows = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary  \\\n",
       "0  Good Quality Dog Food   \n",
       "1      Not as Advertised   \n",
       "2  \"Delight\" says it all   \n",
       "3         Cough Medicine   \n",
       "4            Great taffy   \n",
       "\n",
       "                                                                                                                                                                                                      Text  \n",
       "0  I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...  \n",
       "1           Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".  \n",
       "2  This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...  \n",
       "3  If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...  \n",
       "4                                                             Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['Text'],inplace=True) \n",
    "data.dropna(axis=0,inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words =set( stopwords.words('english'))\n",
    "def textCleaner(text):\n",
    "    newString = text.lower()\n",
    "    newString = re.sub('/\\*[()]',' ',newString)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping.keys() else t for t in newString.split()])\n",
    "    newString = re.sub('\\'s' , '',text)\n",
    "    newString = re.sub('[^a-zA-Z]',\" \",newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = [t for t in newString.split() if not t in stop_words ]\n",
    "    long_words=[]\n",
    "    for i in newString:\n",
    "        if len(i)>=3:                  \n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()\n",
    "\n",
    "cleaned_text = []\n",
    "for t in data['Text']:\n",
    "    cleaned_text.append(textCleaner(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_cleaner(text):\n",
    "    newString = re.sub('\"','', text)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
    "    newString = newString.lower()\n",
    "    tokens=newString.split()\n",
    "    newString=''\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                 \n",
    "            newString=newString+i+' '  \n",
    "    return newString\n",
    "\n",
    "\n",
    "cleaned_summary = []\n",
    "for t in data['Summary']:\n",
    "    cleaned_summary.append(summary_cleaner(t))\n",
    "\n",
    "data['cleaned_text']=cleaned_text\n",
    "data['cleaned_summary']=cleaned_summary\n",
    "data['cleaned_summary'].replace('', np.nan, inplace=True)\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                   bought several Vitality canned dog food products found good quality The product looks like stew processed meat smells better Labrador finicky appreciates product better\n",
       "1                                                                  Product arrived labeled Jumbo Salted Peanuts peanuts actually small sized unsalted Not sure error vendor intended represent product Jumbo\n",
       "2    This confection around centuries light pillowy citrus gelatin nuts case Filberts And cut tiny squares liberally coated powdered sugar And tiny mouthful heaven Not chewy flavorful highly recommend ...\n",
       "3                                                                       looking secret ingredient Robitussin believe found got addition Root Beer Extract ordered good made cherry soda The flavor medicinal\n",
       "4                                                                                                                  Great taffy great price There wide assortment yummy taffy Delivery quick taffy lover deal\n",
       "5    got wild hair taffy ordered five pound bag The taffy enjoyable many flavors watermelon root beer melon peppermint grape etc complaint bit much red black licorice flavored pieces particular favorit...\n",
       "6    This saltwater taffy great flavors soft chewy Each candy individually wrapped well None candies stuck together happen expensive version Fralinger Would highly recommend candy served beach themed p...\n",
       "7                                                                                                           This taffy good soft chewy The flavors amazing would definitely recommend buying Very satisfying\n",
       "8                                                                                                                               Right mostly sprouting cats eat grass They love rotate around Wheatgrass Rye\n",
       "9                                                                                                        This healthy dog food Good digestion Also good small puppies dog eats required amount every feeding\n",
       "Name: cleaned_text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cleaned_text'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: bought several Vitality canned dog food products found good quality The product looks like stew processed meat smells better Labrador finicky appreciates product better\n",
      "Summary: good quality dog food \n",
      "\n",
      "\n",
      "Review: Product arrived labeled Jumbo Salted Peanuts peanuts actually small sized unsalted Not sure error vendor intended represent product Jumbo\n",
      "Summary: not as advertised \n",
      "\n",
      "\n",
      "Review: This confection around centuries light pillowy citrus gelatin nuts case Filberts And cut tiny squares liberally coated powdered sugar And tiny mouthful heaven Not chewy flavorful highly recommend yummy treat familiar story Lewis The Lion The Witch The Wardrobe treat seduces Edmund selling Brother Sisters Witch\n",
      "Summary: delight says it all \n",
      "\n",
      "\n",
      "Review: looking secret ingredient Robitussin believe found got addition Root Beer Extract ordered good made cherry soda The flavor medicinal\n",
      "Summary: cough medicine \n",
      "\n",
      "\n",
      "Review: Great taffy great price There wide assortment yummy taffy Delivery quick taffy lover deal\n",
      "Summary: great taffy \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(5):\n",
    "    print(\"Review:\",data['cleaned_text'][i])\n",
    "    print(\"Summary:\",data['cleaned_summary'][i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_summary'] = data['cleaned_summary'].apply(lambda x : '_START_ '+ x + ' _END_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                        _START_ good quality dog food  _END_\n",
       "1                                                            _START_ not as advertised  _END_\n",
       "2                                                          _START_ delight says it all  _END_\n",
       "3                                                               _START_ cough medicine  _END_\n",
       "4                                                                  _START_ great taffy  _END_\n",
       "                                                 ...                                         \n",
       "99995                                                                    _START_ yummy  _END_\n",
       "99996                                                         _START_ tastes like more  _END_\n",
       "99997                                                              _START_ great ramen  _END_\n",
       "99998                                                                    _START_ spicy  _END_\n",
       "99999    _START_ this spicy noodle cures my cold upset stomach and headache every time  _END_\n",
       "Name: cleaned_summary, Length: 88352, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cleaned_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_word_count = []\n",
    "text_word_count = []\n",
    "for i in data['cleaned_text']:\n",
    "    text_word_count.append(len(i.split()))\n",
    "for i in data['cleaned_summary']:\n",
    "    summary_word_count.append(len(i.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.660947120608476\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(text_word_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_text=80 \n",
    "max_len_summary=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val = train_test_split(data['cleaned_text'],data['cleaned_summary'],test_size = 0.1,random_state = 0,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bought several Vitality canned dog food products found good quality The product looks like stew processed meat smells better Labrador finicky appreciates product better'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tokenizer = Tokenizer()\n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "x_tr    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "x_tr    =   pad_sequences(x_tr,  maxlen=max_len_text, padding='post') \n",
    "x_val   =   pad_sequences(x_val, maxlen=max_len_text, padding='post')\n",
    "\n",
    "x_voc_size   =  len(x_tokenizer.word_index) +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tokenizer = Tokenizer()\n",
    "y_tokenizer.fit_on_texts(list(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = y_tokenizer.texts_to_sequences(y_tr)\n",
    "y_val = y_tokenizer.texts_to_sequences(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 13, 14, 2]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = pad_sequences(y_tr,maxlen = max_len_summary , padding= 'post')\n",
    "y_val = pad_sequences(y_val,maxlen = max_len_summary ,padding = 'post')\n",
    "y_vocab_size = len(y_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 13, 14,  2,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': 1,\n",
       " 'end': 2,\n",
       " 'great': 3,\n",
       " 'the': 4,\n",
       " 'good': 5,\n",
       " 'for': 6,\n",
       " 'not': 7,\n",
       " 'and': 8,\n",
       " 'it': 9,\n",
       " 'best': 10,\n",
       " 'my': 11,\n",
       " 'but': 12,\n",
       " 'love': 13,\n",
       " 'this': 14,\n",
       " 'to': 15,\n",
       " 'is': 16,\n",
       " 'coffee': 17,\n",
       " 'tea': 18,\n",
       " 'of': 19,\n",
       " 'product': 20,\n",
       " 'delicious': 21,\n",
       " 'taste': 22,\n",
       " 'very': 23,\n",
       " 'dog': 24,\n",
       " 'like': 25,\n",
       " 'in': 26,\n",
       " 'flavor': 27,\n",
       " 'excellent': 28,\n",
       " 'food': 29,\n",
       " 'these': 30,\n",
       " 'tasty': 31,\n",
       " 'you': 32,\n",
       " 'price': 33,\n",
       " 'yummy': 34,\n",
       " 'too': 35,\n",
       " 'with': 36,\n",
       " 'as': 37,\n",
       " 'favorite': 38,\n",
       " 'ever': 39,\n",
       " 'so': 40,\n",
       " 'are': 41,\n",
       " 'on': 42,\n",
       " 'dogs': 43,\n",
       " 'loves': 44,\n",
       " 'stuff': 45,\n",
       " 'snack': 46,\n",
       " 'just': 47,\n",
       " 'better': 48,\n",
       " 'have': 49,\n",
       " 'no': 50,\n",
       " 'chocolate': 51,\n",
       " 'healthy': 52,\n",
       " 'awesome': 53,\n",
       " 'tastes': 54,\n",
       " 'than': 55,\n",
       " 'free': 56,\n",
       " 'nice': 57,\n",
       " 'them': 58,\n",
       " 'what': 59,\n",
       " 'sweet': 60,\n",
       " 'perfect': 61,\n",
       " 'at': 62,\n",
       " 'bad': 63,\n",
       " 'really': 64,\n",
       " 'one': 65,\n",
       " 'quality': 66,\n",
       " 'yum': 67,\n",
       " 'all': 68,\n",
       " 'treat': 69,\n",
       " 'tasting': 70,\n",
       " 'wonderful': 71,\n",
       " 'your': 72,\n",
       " 'me': 73,\n",
       " 'buy': 74,\n",
       " 'cat': 75,\n",
       " 'be': 76,\n",
       " 'cup': 77,\n",
       " 'little': 78,\n",
       " 'treats': 79,\n",
       " 'can': 80,\n",
       " 'do': 81,\n",
       " 'from': 82,\n",
       " 'hot': 83,\n",
       " 'that': 84,\n",
       " 'they': 85,\n",
       " 'if': 86,\n",
       " 'amazing': 87,\n",
       " 'easy': 88,\n",
       " 'sugar': 89,\n",
       " 'much': 90,\n",
       " 'chips': 91,\n",
       " 'more': 92,\n",
       " 'gluten': 93,\n",
       " 'organic': 94,\n",
       " 'will': 95,\n",
       " 'was': 96,\n",
       " 'popcorn': 97,\n",
       " 'ok': 98,\n",
       " 'mix': 99,\n",
       " 'cats': 100,\n",
       " 'drink': 101,\n",
       " 'way': 102,\n",
       " 'value': 103,\n",
       " 'pretty': 104,\n",
       " 'or': 105,\n",
       " 'green': 106,\n",
       " 'strong': 107,\n",
       " 'cookies': 108,\n",
       " 'amazon': 109,\n",
       " 'fantastic': 110,\n",
       " 'low': 111,\n",
       " 'only': 112,\n",
       " 'out': 113,\n",
       " 'up': 114,\n",
       " 'works': 115,\n",
       " 'our': 116,\n",
       " 'cereal': 117,\n",
       " 'an': 118,\n",
       " 'happy': 119,\n",
       " 'real': 120,\n",
       " 'get': 121,\n",
       " 'deal': 122,\n",
       " 'salt': 123,\n",
       " 'sauce': 124,\n",
       " 'made': 125,\n",
       " 'does': 126,\n",
       " 'eat': 127,\n",
       " 'candy': 128,\n",
       " 'bar': 129,\n",
       " 'high': 130,\n",
       " 'go': 131,\n",
       " 'rice': 132,\n",
       " 'alternative': 133,\n",
       " 'expensive': 134,\n",
       " 'baby': 135,\n",
       " 'time': 136,\n",
       " 'loved': 137,\n",
       " 'new': 138,\n",
       " 'fresh': 139,\n",
       " 'oil': 140,\n",
       " 'water': 141,\n",
       " 'would': 142,\n",
       " 'hard': 143,\n",
       " 'there': 144,\n",
       " 'by': 145,\n",
       " 'natural': 146,\n",
       " 'energy': 147,\n",
       " 'old': 148,\n",
       " 'wow': 149,\n",
       " 'pasta': 150,\n",
       " 'had': 151,\n",
       " 'bars': 152,\n",
       " 'find': 153,\n",
       " 'cups': 154,\n",
       " 'worth': 155,\n",
       " 'dark': 156,\n",
       " 'well': 157,\n",
       " 'bread': 158,\n",
       " 'did': 159,\n",
       " 'review': 160,\n",
       " 'quick': 161,\n",
       " 'gift': 162,\n",
       " 'use': 163,\n",
       " 'makes': 164,\n",
       " 'blend': 165,\n",
       " 'am': 166,\n",
       " 'small': 167,\n",
       " 'breakfast': 168,\n",
       " 'coconut': 169,\n",
       " 'has': 170,\n",
       " 'super': 171,\n",
       " 'expected': 172,\n",
       " 'some': 173,\n",
       " 'service': 174,\n",
       " 'ginger': 175,\n",
       " 'smooth': 176,\n",
       " 'spicy': 177,\n",
       " 'okay': 178,\n",
       " 'money': 179,\n",
       " 'big': 180,\n",
       " 'bit': 181,\n",
       " 'packaging': 182,\n",
       " 'milk': 183,\n",
       " 'salty': 184,\n",
       " 'don': 185,\n",
       " 'disappointed': 186,\n",
       " 'we': 187,\n",
       " 'make': 188,\n",
       " 'shipping': 189,\n",
       " 'kids': 190,\n",
       " 'soup': 191,\n",
       " 'decaf': 192,\n",
       " 'syrup': 193,\n",
       " 'again': 194,\n",
       " 'right': 195,\n",
       " 'other': 196,\n",
       " 'refreshing': 197,\n",
       " 'without': 198,\n",
       " 'far': 199,\n",
       " 'even': 200,\n",
       " 'chicken': 201,\n",
       " 'nothing': 202,\n",
       " 'butter': 203,\n",
       " 'convenient': 204,\n",
       " 'could': 205,\n",
       " 'pack': 206,\n",
       " 'light': 207,\n",
       " 'fast': 208,\n",
       " 'beware': 209,\n",
       " 'about': 210,\n",
       " 'chai': 211,\n",
       " 'found': 212,\n",
       " 'bitter': 213,\n",
       " 'absolutely': 214,\n",
       " 'black': 215,\n",
       " 'work': 216,\n",
       " 'cookie': 217,\n",
       " 'enough': 218,\n",
       " 'soda': 219,\n",
       " 'horrible': 220,\n",
       " 'its': 221,\n",
       " 'ingredients': 222,\n",
       " 'cheese': 223,\n",
       " 'juice': 224,\n",
       " 'jerky': 225,\n",
       " 'vanilla': 226,\n",
       " 'decent': 227,\n",
       " 'roast': 228,\n",
       " 'item': 229,\n",
       " 'now': 230,\n",
       " 'bold': 231,\n",
       " 'noodles': 232,\n",
       " 'peanut': 233,\n",
       " 'still': 234,\n",
       " 'honey': 235,\n",
       " 'flavors': 236,\n",
       " 'cocoa': 237,\n",
       " 'try': 238,\n",
       " 'dry': 239,\n",
       " 'terrible': 240,\n",
       " 'first': 241,\n",
       " 'greenies': 242,\n",
       " 'poor': 243,\n",
       " 'most': 244,\n",
       " 'awful': 245,\n",
       " 'size': 246,\n",
       " 'stale': 247,\n",
       " 'thing': 248,\n",
       " 'nuts': 249,\n",
       " 'protein': 250,\n",
       " 'fruit': 251,\n",
       " 'when': 252,\n",
       " 'fun': 253,\n",
       " 'less': 254,\n",
       " 'bag': 255,\n",
       " 'after': 256,\n",
       " 'over': 257,\n",
       " 'stars': 258,\n",
       " 'crackers': 259,\n",
       " 'crunchy': 260,\n",
       " 'choice': 261,\n",
       " 'never': 262,\n",
       " 'used': 263,\n",
       " 'rich': 264,\n",
       " 'different': 265,\n",
       " 'cannot': 266,\n",
       " 'white': 267,\n",
       " 'finally': 268,\n",
       " 'flavored': 269,\n",
       " 'beef': 270,\n",
       " 'diet': 271,\n",
       " 'another': 272,\n",
       " 'meal': 273,\n",
       " 'gum': 274,\n",
       " 'toy': 275,\n",
       " 'must': 276,\n",
       " 'how': 277,\n",
       " 'keurig': 278,\n",
       " 'flavorful': 279,\n",
       " 'texture': 280,\n",
       " 'fine': 281,\n",
       " 'order': 282,\n",
       " 'off': 283,\n",
       " 'yuck': 284,\n",
       " 'addictive': 285,\n",
       " 'why': 286,\n",
       " 'simply': 287,\n",
       " 'pricey': 288,\n",
       " 'quite': 289,\n",
       " 'who': 290,\n",
       " 'likes': 291,\n",
       " 'tried': 292,\n",
       " 'substitute': 293,\n",
       " 'granola': 294,\n",
       " 'instant': 295,\n",
       " 'day': 296,\n",
       " 'brand': 297,\n",
       " 'picky': 298,\n",
       " 'fat': 299,\n",
       " 'whole': 300,\n",
       " 'beans': 301,\n",
       " 'weak': 302,\n",
       " 'long': 303,\n",
       " 'wrong': 304,\n",
       " 'were': 305,\n",
       " 'special': 306,\n",
       " 'back': 307,\n",
       " 'down': 308,\n",
       " 'cans': 309,\n",
       " 'got': 310,\n",
       " 'oh': 311,\n",
       " 'pop': 312,\n",
       " 'disappointing': 313,\n",
       " 'tasted': 314,\n",
       " 'pumpkin': 315,\n",
       " 'store': 316,\n",
       " 'fabulous': 317,\n",
       " 'overpriced': 318,\n",
       " 'full': 319,\n",
       " 'cheaper': 320,\n",
       " 'goodness': 321,\n",
       " 'chews': 322,\n",
       " 'worst': 323,\n",
       " 'almost': 324,\n",
       " 'training': 325,\n",
       " 'every': 326,\n",
       " 'oatmeal': 327,\n",
       " 'same': 328,\n",
       " 'market': 329,\n",
       " 'french': 330,\n",
       " 'calories': 331,\n",
       " 'box': 332,\n",
       " 'kind': 333,\n",
       " 'waste': 334,\n",
       " 'lemon': 335,\n",
       " 'iced': 336,\n",
       " 'always': 337,\n",
       " 'variety': 338,\n",
       " 'house': 339,\n",
       " 'here': 340,\n",
       " 'life': 341,\n",
       " 'need': 342,\n",
       " 'something': 343,\n",
       " 'home': 344,\n",
       " 'soft': 345,\n",
       " 'two': 346,\n",
       " 'mild': 347,\n",
       " 'puppy': 348,\n",
       " 'em': 349,\n",
       " 'chip': 350,\n",
       " 'wheat': 351,\n",
       " 'cherry': 352,\n",
       " 'lovers': 353,\n",
       " 'think': 354,\n",
       " 'want': 355,\n",
       " 'own': 356,\n",
       " 'regular': 357,\n",
       " 'customer': 358,\n",
       " 'pepper': 359,\n",
       " 'yet': 360,\n",
       " 'recommended': 361,\n",
       " 'spice': 362,\n",
       " 'health': 363,\n",
       " 'corn': 364,\n",
       " 'powder': 365,\n",
       " 'licorice': 366,\n",
       " 'pure': 367,\n",
       " 'olive': 368,\n",
       " 'any': 369,\n",
       " 'many': 370,\n",
       " 'purchase': 371,\n",
       " 'canned': 372,\n",
       " 'nut': 373,\n",
       " 'around': 374,\n",
       " 'bland': 375,\n",
       " 'family': 376,\n",
       " 'calorie': 377,\n",
       " 'gf': 378,\n",
       " 'espresso': 379,\n",
       " 'seasoning': 380,\n",
       " 'snacks': 381,\n",
       " 'seeds': 382,\n",
       " 'formula': 383,\n",
       " 'smell': 384,\n",
       " 'sure': 385,\n",
       " 'smells': 386,\n",
       " 'almonds': 387,\n",
       " 'surprisingly': 388,\n",
       " 'please': 389,\n",
       " 'red': 390,\n",
       " 'bears': 391,\n",
       " 'should': 392,\n",
       " 'where': 393,\n",
       " 'those': 394,\n",
       " 'son': 395,\n",
       " 'idea': 396,\n",
       " 'carb': 397,\n",
       " 'dried': 398,\n",
       " 'say': 399,\n",
       " 'lot': 400,\n",
       " 'liked': 401,\n",
       " 'heaven': 402,\n",
       " 'last': 403,\n",
       " 'china': 404,\n",
       " 'world': 405,\n",
       " 'lover': 406,\n",
       " 'potato': 407,\n",
       " 'brown': 408,\n",
       " 'bags': 409,\n",
       " 'pleased': 410,\n",
       " 'morning': 411,\n",
       " 'yes': 412,\n",
       " 'eating': 413,\n",
       " 'exactly': 414,\n",
       " 'hit': 415,\n",
       " 'wish': 416,\n",
       " 'oz': 417,\n",
       " 'cheap': 418,\n",
       " 'outstanding': 419,\n",
       " 'grey': 420,\n",
       " 'know': 421,\n",
       " 'pork': 422,\n",
       " 'highly': 423,\n",
       " 'original': 424,\n",
       " 'cake': 425,\n",
       " 'aftertaste': 426,\n",
       " 'chili': 427,\n",
       " 'company': 428,\n",
       " 'average': 429,\n",
       " 'option': 430,\n",
       " 'didn': 431,\n",
       " 'delivery': 432,\n",
       " 'sour': 433,\n",
       " 'orange': 434,\n",
       " 'delish': 435,\n",
       " 'bought': 436,\n",
       " 'starbucks': 437,\n",
       " 'maple': 438,\n",
       " 'acid': 439,\n",
       " 'filling': 440,\n",
       " 'fan': 441,\n",
       " 'change': 442,\n",
       " 'give': 443,\n",
       " 'says': 444,\n",
       " 'crazy': 445,\n",
       " 'earl': 446,\n",
       " 'been': 447,\n",
       " 'simple': 448,\n",
       " 'cinnamon': 449,\n",
       " 'chewy': 450,\n",
       " 'available': 451,\n",
       " 'crunch': 452,\n",
       " 'satisfying': 453,\n",
       " 'star': 454,\n",
       " 'hair': 455,\n",
       " 'lots': 456,\n",
       " 'raw': 457,\n",
       " 'cooking': 458,\n",
       " 'fiber': 459,\n",
       " 'teeth': 460,\n",
       " 'ice': 461,\n",
       " 'looking': 462,\n",
       " 'package': 463,\n",
       " 'nasty': 464,\n",
       " 'warning': 465,\n",
       " 'baking': 466,\n",
       " 'miracle': 467,\n",
       " 'chew': 468,\n",
       " 'weight': 469,\n",
       " 'gourmet': 470,\n",
       " 'date': 471,\n",
       " 'switch': 472,\n",
       " 'products': 473,\n",
       " 'needs': 474,\n",
       " 'artificial': 475,\n",
       " 'arrived': 476,\n",
       " 'their': 477,\n",
       " 'apple': 478,\n",
       " 'gummi': 479,\n",
       " 'gross': 480,\n",
       " 'nutritious': 481,\n",
       " 'things': 482,\n",
       " 'doesn': 483,\n",
       " 'though': 484,\n",
       " 'contains': 485,\n",
       " 'non': 486,\n",
       " 'delight': 487,\n",
       " 'clean': 488,\n",
       " 'misleading': 489,\n",
       " 'cream': 490,\n",
       " 'true': 491,\n",
       " 'may': 492,\n",
       " 'pie': 493,\n",
       " 'soy': 494,\n",
       " 'advertised': 495,\n",
       " 'terrific': 496,\n",
       " 'cold': 497,\n",
       " 'grain': 498,\n",
       " 'kitty': 499,\n",
       " 'cost': 500,\n",
       " 'disgusting': 501,\n",
       " 'dented': 502,\n",
       " 'mountain': 503,\n",
       " 'blue': 504,\n",
       " 'aroma': 505,\n",
       " 'us': 506,\n",
       " 'ounce': 507,\n",
       " 'definitely': 508,\n",
       " 'top': 509,\n",
       " 'impressed': 510,\n",
       " 'changed': 511,\n",
       " 'noodle': 512,\n",
       " 'extra': 513,\n",
       " 'ordered': 514,\n",
       " 'people': 515,\n",
       " 'keep': 516,\n",
       " 'everything': 517,\n",
       " 'large': 518,\n",
       " 'broken': 519,\n",
       " 'earth': 520,\n",
       " 'actually': 521,\n",
       " 'plastic': 522,\n",
       " 'maybe': 523,\n",
       " 'years': 524,\n",
       " 'mint': 525,\n",
       " 'newman': 526,\n",
       " 'pleasant': 527,\n",
       " 'healthier': 528,\n",
       " 'bite': 529,\n",
       " 'meh': 530,\n",
       " 'cracker': 531,\n",
       " 'read': 532,\n",
       " 'brew': 533,\n",
       " 'away': 534,\n",
       " 'year': 535,\n",
       " 'thought': 536,\n",
       " 'popchips': 537,\n",
       " 'mini': 538,\n",
       " 'plus': 539,\n",
       " 'stomach': 540,\n",
       " 'vegan': 541,\n",
       " 'beautiful': 542,\n",
       " 'foods': 543,\n",
       " 'pet': 544,\n",
       " 'teas': 545,\n",
       " 'then': 546,\n",
       " 'almond': 547,\n",
       " 'interesting': 548,\n",
       " 'homemade': 549,\n",
       " 'live': 550,\n",
       " 're': 551,\n",
       " 'bbq': 552,\n",
       " 'problems': 553,\n",
       " 'gummy': 554,\n",
       " 'recipe': 555,\n",
       " 'dental': 556,\n",
       " 'help': 557,\n",
       " 'banana': 558,\n",
       " 'flour': 559,\n",
       " 'fish': 560,\n",
       " 'doggie': 561,\n",
       " 'beverage': 562,\n",
       " 'medium': 563,\n",
       " 'daughter': 564,\n",
       " 'replacement': 565,\n",
       " 'satisfied': 566,\n",
       " 'nutrition': 567,\n",
       " 'salmon': 568,\n",
       " 'looks': 569,\n",
       " 'add': 570,\n",
       " 'lovely': 571,\n",
       " 'greatest': 572,\n",
       " 'thin': 573,\n",
       " 'dinner': 574,\n",
       " 'wanted': 575,\n",
       " 'enjoy': 576,\n",
       " 'meat': 577,\n",
       " 'goes': 578,\n",
       " 'added': 579,\n",
       " 'priced': 580,\n",
       " 'addicted': 581,\n",
       " 'kick': 582,\n",
       " 'nom': 583,\n",
       " 'thank': 584,\n",
       " 'mustard': 585,\n",
       " 'gold': 586,\n",
       " 'reviews': 587,\n",
       " 'close': 588,\n",
       " 'creamy': 589,\n",
       " 'sodium': 590,\n",
       " 'stevia': 591,\n",
       " 'drinks': 592,\n",
       " 'bottle': 593,\n",
       " 'mixed': 594,\n",
       " 'surprise': 595,\n",
       " 'wild': 596,\n",
       " 'kid': 597,\n",
       " 'seems': 598,\n",
       " 'classic': 599,\n",
       " 'unique': 600,\n",
       " 'brownies': 601,\n",
       " 'husband': 602,\n",
       " 'crack': 603,\n",
       " 'keeps': 604,\n",
       " 'rip': 605,\n",
       " 'addicting': 606,\n",
       " 'else': 607,\n",
       " 'shampoo': 608,\n",
       " 'pods': 609,\n",
       " 'delightful': 610,\n",
       " 'versatile': 611,\n",
       " 'omg': 612,\n",
       " 'winner': 613,\n",
       " 'crispy': 614,\n",
       " 'everyone': 615,\n",
       " 'allergies': 616,\n",
       " 'superb': 617,\n",
       " 'sticks': 618,\n",
       " 'look': 619,\n",
       " 'machine': 620,\n",
       " 'ingredient': 621,\n",
       " 'premium': 622,\n",
       " 'truly': 623,\n",
       " 'berry': 624,\n",
       " 'sick': 625,\n",
       " 'paws': 626,\n",
       " 'buying': 627,\n",
       " 'pancakes': 628,\n",
       " 'save': 629,\n",
       " 'glad': 630,\n",
       " 'italian': 631,\n",
       " 'plain': 632,\n",
       " 'take': 633,\n",
       " 'name': 634,\n",
       " 'surprised': 635,\n",
       " 'pizza': 636,\n",
       " 'tree': 637,\n",
       " 'biscuits': 638,\n",
       " 'received': 639,\n",
       " 'english': 640,\n",
       " 'she': 641,\n",
       " 'bran': 642,\n",
       " 'staple': 643,\n",
       " 'peanuts': 644,\n",
       " 'hate': 645,\n",
       " 'bay': 646,\n",
       " 'tart': 647,\n",
       " 'dressing': 648,\n",
       " 'wine': 649,\n",
       " 'before': 650,\n",
       " 'worked': 651,\n",
       " 'packaged': 652,\n",
       " 'description': 653,\n",
       " 'half': 654,\n",
       " 'fruity': 655,\n",
       " 'haribo': 656,\n",
       " 'rocks': 657,\n",
       " 'per': 658,\n",
       " 'strawberry': 659,\n",
       " 'cheesy': 660,\n",
       " 'hands': 661,\n",
       " 'mouth': 662,\n",
       " 'making': 663,\n",
       " 'experience': 664,\n",
       " 'favorites': 665,\n",
       " 'sweetener': 666,\n",
       " 'san': 667,\n",
       " 'mmm': 668,\n",
       " 'ramen': 669,\n",
       " 'expiration': 670,\n",
       " 'mom': 671,\n",
       " 'vinegar': 672,\n",
       " 'sensitive': 673,\n",
       " 'baked': 674,\n",
       " 'curry': 675,\n",
       " 'source': 676,\n",
       " 'lunch': 677,\n",
       " 'approved': 678,\n",
       " 'slightly': 679,\n",
       " 'rinds': 680,\n",
       " 'others': 681,\n",
       " 'microwave': 682,\n",
       " 'lipton': 683,\n",
       " 'salad': 684,\n",
       " 'style': 685,\n",
       " 'wife': 686,\n",
       " 'packs': 687,\n",
       " 'count': 688,\n",
       " 'helps': 689,\n",
       " 'boxes': 690,\n",
       " 'care': 691,\n",
       " 'chocolates': 692,\n",
       " 'stores': 693,\n",
       " 'cute': 694,\n",
       " 'problem': 695,\n",
       " 'smaller': 696,\n",
       " 'gets': 697,\n",
       " 'weird': 698,\n",
       " 'kit': 699,\n",
       " 'version': 700,\n",
       " 'difference': 701,\n",
       " 'huge': 702,\n",
       " 'raspberry': 703,\n",
       " 'five': 704,\n",
       " 'seller': 705,\n",
       " 'pb': 706,\n",
       " 'feel': 707,\n",
       " 'totally': 708,\n",
       " 'busy': 709,\n",
       " 'magic': 710,\n",
       " 'solid': 711,\n",
       " 'thanks': 712,\n",
       " 'beer': 713,\n",
       " 'strange': 714,\n",
       " 'brownie': 715,\n",
       " 'both': 716,\n",
       " 'anything': 717,\n",
       " 'hour': 718,\n",
       " 'into': 719,\n",
       " 'heat': 720,\n",
       " 'bacon': 721,\n",
       " 'going': 722,\n",
       " 'extremely': 723,\n",
       " 'addition': 724,\n",
       " 'sea': 725,\n",
       " 'dessert': 726,\n",
       " 'summer': 727,\n",
       " 'effective': 728,\n",
       " 'roasted': 729,\n",
       " 'caffeine': 730,\n",
       " 'convenience': 731,\n",
       " 'boost': 732,\n",
       " 'bean': 733,\n",
       " 'disappointment': 734,\n",
       " 'saver': 735,\n",
       " 'damaged': 736,\n",
       " 'matcha': 737,\n",
       " 'pick': 738,\n",
       " 'balance': 739,\n",
       " 'come': 740,\n",
       " 'plant': 741,\n",
       " 'might': 742,\n",
       " 'picture': 743,\n",
       " 'second': 744,\n",
       " 'buyer': 745,\n",
       " 'remember': 746,\n",
       " 'guilt': 747,\n",
       " 'her': 748,\n",
       " 'gone': 749,\n",
       " 'everyday': 750,\n",
       " 'shake': 751,\n",
       " 'prefer': 752,\n",
       " 'darn': 753,\n",
       " 'recommend': 754,\n",
       " 'ones': 755,\n",
       " 'while': 756,\n",
       " 'agave': 757,\n",
       " 'francisco': 758,\n",
       " 'extract': 759,\n",
       " 'few': 760,\n",
       " 'grass': 761,\n",
       " 'lime': 762,\n",
       " 'loose': 763,\n",
       " 'bargain': 764,\n",
       " 'mango': 765,\n",
       " 'raisins': 766,\n",
       " 'cook': 767,\n",
       " 'peach': 768,\n",
       " 'brands': 769,\n",
       " 'finicky': 770,\n",
       " 'jelly': 771,\n",
       " 'msg': 772,\n",
       " 'gave': 773,\n",
       " 'he': 774,\n",
       " 'melted': 775,\n",
       " 'mess': 776,\n",
       " 'zero': 777,\n",
       " 'affordable': 778,\n",
       " 'three': 779,\n",
       " 'watch': 780,\n",
       " 'issues': 781,\n",
       " 'thai': 782,\n",
       " 'leaves': 783,\n",
       " 'believe': 784,\n",
       " 'side': 785,\n",
       " 'taco': 786,\n",
       " 'rub': 787,\n",
       " 'hazelnut': 788,\n",
       " 'short': 789,\n",
       " 'rock': 790,\n",
       " 'dr': 791,\n",
       " 'ground': 792,\n",
       " 'allergy': 793,\n",
       " 'job': 794,\n",
       " 'absolute': 795,\n",
       " 'batch': 796,\n",
       " 'careful': 797,\n",
       " 'paste': 798,\n",
       " 'instead': 799,\n",
       " 'month': 800,\n",
       " 'tummy': 801,\n",
       " 'days': 802,\n",
       " 'bones': 803,\n",
       " 'toddler': 804,\n",
       " 'handy': 805,\n",
       " 'cashews': 806,\n",
       " 'open': 807,\n",
       " 'dont': 808,\n",
       " 'stop': 809,\n",
       " 'chef': 810,\n",
       " 'pieces': 811,\n",
       " 'needed': 812,\n",
       " 'kitchen': 813,\n",
       " 'perfectly': 814,\n",
       " 'friendly': 815,\n",
       " 'getting': 816,\n",
       " 'cal': 817,\n",
       " 'zico': 818,\n",
       " 'messy': 819,\n",
       " 'babies': 820,\n",
       " 'vegetarian': 821,\n",
       " 'stash': 822,\n",
       " 'nature': 823,\n",
       " 'caramel': 824,\n",
       " 'nutty': 825,\n",
       " 'kona': 826,\n",
       " 'pup': 827,\n",
       " 'fix': 828,\n",
       " 'joe': 829,\n",
       " 'odd': 830,\n",
       " 'leaf': 831,\n",
       " 'edible': 832,\n",
       " 'described': 833,\n",
       " 'carbonated': 834,\n",
       " 'bulk': 835,\n",
       " 'grocery': 836,\n",
       " 'eater': 837,\n",
       " 'being': 838,\n",
       " 'touch': 839,\n",
       " 'usa': 840,\n",
       " 'tuna': 841,\n",
       " 'using': 842,\n",
       " 'smart': 843,\n",
       " 'tomato': 844,\n",
       " 'eats': 845,\n",
       " 'tangy': 846,\n",
       " 'mmmmm': 847,\n",
       " 'thick': 848,\n",
       " 'pay': 849,\n",
       " 'pancake': 850,\n",
       " 'lab': 851,\n",
       " 'expired': 852,\n",
       " 'results': 853,\n",
       " 'superior': 854,\n",
       " 'beat': 855,\n",
       " 'incredible': 856,\n",
       " 'fog': 857,\n",
       " 'watery': 858,\n",
       " 'tasteless': 859,\n",
       " 'amount': 860,\n",
       " 'sardines': 861,\n",
       " 'gravy': 862,\n",
       " 'expect': 863,\n",
       " 'yumm': 864,\n",
       " 'shipped': 865,\n",
       " 'tully': 866,\n",
       " 'mediocre': 867,\n",
       " 'standard': 868,\n",
       " 'country': 869,\n",
       " 'senseo': 870,\n",
       " 'kashi': 871,\n",
       " 'berries': 872,\n",
       " 'cool': 873,\n",
       " 'probably': 874,\n",
       " 'robust': 875,\n",
       " 'fair': 876,\n",
       " 'control': 877,\n",
       " 'local': 878,\n",
       " 'quaker': 879,\n",
       " 'hooked': 880,\n",
       " 'quickly': 881,\n",
       " 'tough': 882,\n",
       " 'sticky': 883,\n",
       " 'kitties': 884,\n",
       " 'daily': 885,\n",
       " 'false': 886,\n",
       " 'grade': 887,\n",
       " 'stick': 888,\n",
       " 'dairy': 889,\n",
       " 'turkey': 890,\n",
       " 'mac': 891,\n",
       " 'muffins': 892,\n",
       " 'longer': 893,\n",
       " 'movie': 894,\n",
       " 'liver': 895,\n",
       " 'herbal': 896,\n",
       " 'also': 897,\n",
       " 'cherries': 898,\n",
       " 'bottles': 899,\n",
       " 'garlic': 900,\n",
       " 'dream': 901,\n",
       " 'bone': 902,\n",
       " 'coco': 903,\n",
       " 'online': 904,\n",
       " 'seed': 905,\n",
       " 'enjoyed': 906,\n",
       " 'because': 907,\n",
       " 'advertising': 908,\n",
       " 'check': 909,\n",
       " 'pretzels': 910,\n",
       " 'pudding': 911,\n",
       " 'pictured': 912,\n",
       " 'steak': 913,\n",
       " 'mints': 914,\n",
       " 'mostly': 915,\n",
       " 'authentic': 916,\n",
       " 'bpa': 917,\n",
       " 'color': 918,\n",
       " 'gas': 919,\n",
       " 'amazingly': 920,\n",
       " 'expectations': 921,\n",
       " 'tiny': 922,\n",
       " 'somewhat': 923,\n",
       " 'nectar': 924,\n",
       " 'fake': 925,\n",
       " 'basic': 926,\n",
       " 'coffe': 927,\n",
       " 'rawhide': 928,\n",
       " 'basket': 929,\n",
       " 'label': 930,\n",
       " 'increase': 931,\n",
       " 'yogurt': 932,\n",
       " 'pomegranate': 933,\n",
       " 'safe': 934,\n",
       " 'prunes': 935,\n",
       " 'sooo': 936,\n",
       " 'breath': 937,\n",
       " 'least': 938,\n",
       " 'blueberry': 939,\n",
       " 'candies': 940,\n",
       " 'serving': 941,\n",
       " 'com': 942,\n",
       " 'lower': 943,\n",
       " 'anymore': 944,\n",
       " 'll': 945,\n",
       " 'punch': 946,\n",
       " 'gives': 947,\n",
       " 'soothing': 948,\n",
       " 'christmas': 949,\n",
       " 'stay': 950,\n",
       " 'pantry': 951,\n",
       " 'pleasantly': 952,\n",
       " 'bring': 953,\n",
       " 'eh': 954,\n",
       " 'sent': 955,\n",
       " 'pops': 956,\n",
       " 'friend': 957,\n",
       " 'skin': 958,\n",
       " 'his': 959,\n",
       " 'theater': 960,\n",
       " 'heavenly': 961,\n",
       " 'see': 962,\n",
       " 'put': 963,\n",
       " 'hamburger': 964,\n",
       " 'pill': 965,\n",
       " 'twinings': 966,\n",
       " 'crystal': 967,\n",
       " 'drinking': 968,\n",
       " 'won': 969,\n",
       " 'sorry': 970,\n",
       " 'cacao': 971,\n",
       " 'bowl': 972,\n",
       " 'anyone': 973,\n",
       " 'chaser': 974,\n",
       " 'cheez': 975,\n",
       " 'spices': 976,\n",
       " 'childhood': 977,\n",
       " 'thumbs': 978,\n",
       " 'ate': 979,\n",
       " 'tips': 980,\n",
       " 'bonsai': 981,\n",
       " 'illy': 982,\n",
       " 'broccoli': 983,\n",
       " 'addiction': 984,\n",
       " 'purchased': 985,\n",
       " 'combination': 986,\n",
       " 'except': 987,\n",
       " 'bisquick': 988,\n",
       " 'grains': 989,\n",
       " 'drinker': 990,\n",
       " 'said': 991,\n",
       " 'hips': 992,\n",
       " 'chipotle': 993,\n",
       " 'crisp': 994,\n",
       " 'liquid': 995,\n",
       " 'yourself': 996,\n",
       " 'dangerous': 997,\n",
       " 'god': 998,\n",
       " 'helper': 999,\n",
       " 'wholesome': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 80)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 80, 500)      24915000    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 80, 500), (N 2002000     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 80, 500), (N 2002000     lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 500)    7048000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 80, 500), (N 2002000     lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 500),  2002000     embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 500),  500500      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 1000)   0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 14096)  14110096    concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 54,581,596\n",
      "Trainable params: 54,581,596\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 500\n",
    "encoder_input = Input(shape = (max_len_text,))\n",
    "embedding1 =Embedding(x_voc_size ,latent_dim,trainable= True)(encoder_input)\n",
    "\n",
    "lstm1 = LSTM(latent_dim , return_sequences=True , return_state= True)\n",
    "lstm1_outputs ,lstm1_state_h,lstm_state_c = lstm1(embedding1)\n",
    "\n",
    "lstm2 = LSTM(latent_dim , return_sequences = True , return_state = True)\n",
    "lstm2_outputs , lstm2_state_h, lstm2_state_c = lstm2(lstm1_outputs)\n",
    "\n",
    "lstm3 = LSTM(latent_dim , return_sequences = True , return_state = True)\n",
    "encoder_outputs , state_h, state_c = lstm3(lstm2_outputs)\n",
    "\n",
    "decoder_inputs = Input(shape=(None,)) \n",
    "dec_emb_layer = Embedding(y_vocab_size, latent_dim,trainable=True) \n",
    "dec_emb = dec_emb_layer(decoder_inputs) \n",
    "\n",
    "decoder_lstm = LSTM(latent_dim , return_sequences=True, return_state=True) \n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
    "\n",
    "attn_layer = AttentionLayer(name='attention_layer') \n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
    "\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "decoder_dense = TimeDistributed(Dense(y_vocab_size, activation='softmax')) \n",
    "decoder_outputs = decoder_dense(decoder_concat_input) \n",
    "\n",
    "model = Model([encoder_input, decoder_inputs], decoder_outputs) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',loss = 'sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 13, 14,  2,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr[:,:-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13],\n",
       "       [14],\n",
       "       [ 2],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79516 samples, validate on 8836 samples\n",
      "Epoch 1/10\n",
      "79516/79516 [==============================] - 1796s 23ms/sample - loss: 2.8950 - val_loss: 2.5148\n",
      "Epoch 2/10\n",
      "79516/79516 [==============================] - 1545s 19ms/sample - loss: 2.5024 - val_loss: 2.3489\n",
      "Epoch 3/10\n",
      "79516/79516 [==============================] - 1514s 19ms/sample - loss: 2.3431 - val_loss: 2.2615\n",
      "Epoch 4/10\n",
      "79516/79516 [==============================] - 1514s 19ms/sample - loss: 2.2279 - val_loss: 2.2183\n",
      "Epoch 5/10\n",
      "79516/79516 [==============================] - 1505s 19ms/sample - loss: 2.1301 - val_loss: 2.1887\n",
      "Epoch 6/10\n",
      "79516/79516 [==============================] - 1504s 19ms/sample - loss: 2.0421 - val_loss: 2.1779\n",
      "Epoch 7/10\n",
      "79516/79516 [==============================] - 1504s 19ms/sample - loss: 1.9539 - val_loss: 2.1857\n",
      "Epoch 8/10\n",
      "79516/79516 [==============================] - 3518s 44ms/sample - loss: 1.8660 - val_loss: 2.2024\n",
      "Epoch 9/10\n",
      "79516/79516 [==============================] - 1861s 23ms/sample - loss: 1.7784 - val_loss: 2.2257\n",
      "Epoch 10/10\n",
      "79516/79516 [==============================] - 1987s 25ms/sample - loss: 1.6898 - val_loss: 2.2565\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([x_tr,y_tr[:,:-1]] , y_tr.reshape(y_tr.shape[0],y_tr.shape[1],1)[:,1:] , epochs = 10,batch_size=128, validation_data=([x_val,y_val[:,:-1]],y_val.reshape(y_val.shape[0] , y_val.shape[1],1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2391dc3e780>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word \n",
    "reverse_source_word_index=x_tokenizer.index_word \n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inf = inference phase\n",
    "encoder_model = Model(encoder_input,[encoder_outputs,state_h,state_h])\n",
    "\n",
    "decoder_state_h = Input(shape = (latent_dim,))\n",
    "decoder_state_c = Input(shape = (latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape = (max_len_text,latent_dim))\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs)\n",
    "decoder_outputs2,state_h2,state_c2 = decoder_lstm(dec_emb2 , initial_state=[decoder_state_h,decoder_state_c])\n",
    "\n",
    "attn_out_inf , attn_state_inf = attn_layer([decoder_hidden_state_input,decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,decoder_state_h, decoder_state_c],\n",
    "[decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seq(input_seq):\n",
    "    enc_out,e_h,e_c = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0,0] = target_word_index['start']\n",
    "    decoded_sent =''\n",
    "    stop = False\n",
    "    while not stop:\n",
    "        dec_output ,h,c = decoder_model.predict([target_seq] + [enc_out,e_h,e_c])\n",
    "        index = np.argmax(dec_output)\n",
    "        cur_word = reverse_target_word_index[index]\n",
    "        if cur_word != 'end':\n",
    "            decoded_sent = decoded_sent+ cur_word+\" \"\n",
    "        if cur_word == 'end' or len(decoded_sent.split())>max_len_summary:\n",
    "            stop = True\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0,0] = index\n",
    "        e_h,e_c = h,c\n",
    "    return decoded_sent\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'great taste '"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_seq(x_tr[0].reshape(1,max_len_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['like love food the']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tokenizer.sequences_to_texts([y_tr[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userReview(review):\n",
    "    #review = input()\n",
    "    review = 'start ' + textCleaner(review) + ' end'\n",
    "    review_mat = x_tokenizer.texts_to_sequences([review])\n",
    "    review_mat =pad_sequences(review_mat,  maxlen=max_len_text, padding='post') \n",
    "    print(review_mat)\n",
    "    return decode_seq([review_mat])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 484    2   14  405   21  490   17   68    4    7   96  367 1024    4\n",
      "   111   66 7314 6771 5269  118   46  253  112 4054  397    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'delicious '"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userReview('The Food we had enjoyed at the time of dinner. It was really delicious taste with great quality, everything had unique taste which we had ordered, nice arrangement and services from the staff while eating, we found nothing bad about this hotel.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  484     2 22403     3    14  4797     7   928 14180   167   125  2152\n",
      "     37   465   621   317    55   201   174     7   397     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'good stuff '"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userReview('The ambiance was good and the food recommendations were great. We had a traditional Arabian rice and chicken preparation, Kuzhi Manthi. It was our first experience having this dish, and although a bit dry, it tasted great.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
    "        newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if(i!=0):\n",
    "        newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: ordered salmon thursday january received january the salmon delicious the wooden box nice design used store items future \n",
      "Original summary: alaska smokehouse smoked salmon \n",
      "Predicted summary: great gift \n",
      "\n",
      "\n",
      "Review: drank cold could pleased the coffee high quality arabica always notice coffee arabica robusta sweet without sweet mean compare major bottled coffee brand reason alone you keep fridge work offer people without looking like pushing calories along caffeine for long time stock highly sweetened coffee beverages fridge work then noticed people stopped consuming happened around time lost interest level sweetness recommend drink prefer lower level sugar old school arabica coffee types \n",
      "Original summary: it was perfect little sweet without being too sweet \n",
      "Predicted summary: great coffee \n",
      "\n",
      "\n",
      "Review: variety granola and one ranks top favorites crunch granola coconut main taste sweet overly eat snack craving something fills fast satisfies sugar cravings \n",
      "Original summary: great taste \n",
      "Predicted summary: delicious \n",
      "\n",
      "\n",
      "Review: bought dollar tree bags they yummy taste like french fries crunchy going buy bulk pass kid test \n",
      "Original summary: yum \n",
      "Predicted summary: great taste \n",
      "\n",
      "\n",
      "Review: used eating flaxseed brownie hodgson mill brownies super easy make taste great since like dark chocolate usually add little cocoa \n",
      "Original summary: delicious brownie \n",
      "Predicted summary: great brownies \n",
      "\n",
      "\n",
      "Review: picked local grocery store organic brown rice pleasantly surprised cooks really well sticky use bit coconut oil cook organic vegetable broth tastes great typically brown rice lover kind really good kids husband ate asked seconds well was delighted see amazon great price subscribe save \n",
      "Original summary: love this rice \n",
      "Predicted summary: great product \n",
      "\n",
      "\n",
      "Review: stuff oily probably could run car takes cup creamer make change black tan ick \n",
      "Original summary: yuk \n",
      "Predicted summary: not for me \n",
      "\n",
      "\n",
      "Review: the good concentrate product packaging recyclable the good taste rather unripe taste liking \n",
      "Original summary: good not so good \n",
      "Predicted summary: not as good as other flavors \n",
      "\n",
      "\n",
      "Review: mellow great idea soul wants cup coffee bear brew one two lonely cups the big disadvantage instant coffee far concerned serving product abut caffeine compared caffeine brewed cup coffee talking upper end way brew mine want caffeine the flavored versions product even less caffeine per serving although tell this information way comes nescafe website faq the disadvantage suppose whole house fill sound fragrance brewing coffee choose instant alas still given convenience decency beverage buying little single sticks pretty regularly recommended \n",
      "Original summary: pleasant beverage convenient format \n",
      "Predicted summary: great for coffee maker \n",
      "\n",
      "\n",
      "Review: the price right comparison local arts store steal the color dark picture more pastel red set pink anything reccomended measurement usage delivered bubble wrap package \n",
      "Original summary: red or pink \n",
      "Predicted summary: great price for fresh product \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "  print(\"Review:\",seq2text(x_val[i]))\n",
    "  print(\"Original summary:\",seq2summary(y_val[i]))\n",
    "  print(\"Predicted summary:\",decode_seq(x_val[i].reshape(1,max_len_text)))\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
